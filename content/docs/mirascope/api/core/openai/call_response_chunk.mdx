---
# AUTO-GENERATED API DOCUMENTATION - DO NOT EDIT
title: mirascope.core.openai.call_response_chunk
description: API documentation for mirascope.core.openai.call_response_chunk
---

# mirascope.core.openai.call_response_chunk

<ApiType type="Module" />

This module contains the `OpenAICallResponseChunk` class.

<Info title="Usage">

[Streams](/docs/mirascope/learn/streams#handling-streamed-responses)

</Info>

## Classes

### OpenAICallResponseChunk

<ApiType type="Class" />

A convenience wrapper around the OpenAI `ChatCompletionChunk` streamed chunks.

When calling the OpenAI API using a function decorated with `openai_call` and
`stream` set to `True`, the stream will contain `OpenAIResponseChunk` instances with
properties that allow for more convenient access to commonly used attributes.

Example:

```python
from mirascope.core import prompt_template
from mirascope.core.openai import openai_call


@openai_call("gpt-4o-mini", stream=True)
def recommend_book(genre: str) -> str:
    return f"Recommend a {genre} book"


stream = recommend_book("fantasy")  # response is an `OpenAIStream`
for chunk, _ in stream:
    print(chunk.content, end="", flush=True)
```

**Bases:** BaseCallResponseChunk[ChatCompletionChunk, FinishReason]

<AttributesTable
  attributes={[
  {
    "name": "chunk",
    "type": "SkipValidation[ChatCompletionChunk]"
  },
  {
    "name": "content",
    "type": "str",
    "description": "Returns the content for the 0th choice delta."
  },
  {
    "name": "finish_reasons",
    "type": "list[FinishReason]",
    "description": "Returns the finish reasons of the response."
  },
  {
    "name": "model",
    "type": "str",
    "description": "Returns the name of the response model."
  },
  {
    "name": "id",
    "type": "str",
    "description": "Returns the id of the response."
  },
  {
    "name": "usage",
    "type": "CompletionUsage | None",
    "description": "Returns the usage of the chat completion."
  },
  {
    "name": "cached_tokens",
    "type": "int | None",
    "description": "Returns the number of cached tokens."
  },
  {
    "name": "input_tokens",
    "type": "int | None",
    "description": "Returns the number of input tokens."
  },
  {
    "name": "output_tokens",
    "type": "int | None",
    "description": "Returns the number of output tokens."
  },
  {
    "name": "audio",
    "type": "bytes | None",
    "description": "Returns the audio data of the response."
  },
  {
    "name": "audio_transcript",
    "type": "str | None",
    "description": "Returns the transcript of the audio content."
  },
  {
    "name": "cost_metadata",
    "type": "CostMetadata",
    "description": "Returns the cost metadata."
  },
  {
    "name": "common_finish_reasons",
    "type": "list[FinishReason] | None",
    "description": "Provider-agnostic finish reasons."
  }
]}
  contentSubpath="docs/mirascope"
  currentModule="mirascope.core.openai.call_response_chunk"
/>



