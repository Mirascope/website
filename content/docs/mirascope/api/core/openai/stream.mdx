---
# AUTO-GENERATED API DOCUMENTATION - DO NOT EDIT
title: mirascope.core.openai.stream
description: API documentation for mirascope.core.openai.stream
---

# mirascope.core.openai.stream

<ApiType type="Module" />

The `OpenAIStream` class for convenience around streaming LLM calls.

<Info title="Usage">

[Streams](/docs/mirascope/learn/streams)

</Info>

## Classes

### OpenAIStream

<ApiType type="Class" />

A class for convenience around streaming OpenAI LLM calls.

Example:

```python
from mirascope.core import prompt_template
from mirascope.core.openai import openai_call


@openai_call("gpt-4o-mini", stream=True)
def recommend_book(genre: str) -> str:
    return f"Recommend a {genre} book"


stream = recommend_book("fantasy")  # returns `OpenAIStream` instance
for chunk, _ in stream:
    print(chunk.content, end="", flush=True)
```

**Bases:** BaseStream[OpenAICallResponse, OpenAICallResponseChunk, ChatCompletionUserMessageParam, ChatCompletionAssistantMessageParam, ChatCompletionToolMessageParam, ChatCompletionMessageParam, OpenAITool, ChatCompletionToolParam, OpenAIDynamicConfig, OpenAICallParams, FinishReason]

<AttributesTable
  attributes={[
  {
    "name": "audio_id",
    "type": "str | None"
  },
  {
    "name": "cost_metadata",
    "type": "CostMetadata"
  }
]}
  contentSubpath="docs/mirascope"
  currentModule="mirascope.core.openai.stream"
/>



