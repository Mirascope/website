---
# AUTO-GENERATED API DOCUMENTATION - DO NOT EDIT
title: mirascope.core.litellm.call_response_chunk
description: API documentation for mirascope.core.litellm.call_response_chunk
---

# mirascope.core.litellm.call_response_chunk

## <ApiType type="Module" module="mirascope.core.litellm.call_response_chunk" path="core/litellm/call_response_chunk" symbolName="call_response_chunk" /> call_response_chunk

This module contains the `LiteLLMCallResponseChunk` class.

<Info title="Usage">

[Streams](/docs/mirascope/learn/streams#handling-streamed-responses)

</Info>

## Classes

### LiteLLMCallResponseChunk

### <ApiType type="Class" module="mirascope.core.litellm.call_response_chunk" path="core/litellm/call_response_chunk" symbolName="LiteLLMCallResponseChunk" /> LiteLLMCallResponseChunk

A simpler wrapper around `OpenAICallResponse`.

Everything is the same except the `cost` property, which has been updated to use
LiteLLM's cost calculations so that cost tracking works for non-OpenAI models.

**Bases:** OpenAICallResponseChunk



