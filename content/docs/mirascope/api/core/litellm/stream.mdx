---
# AUTO-GENERATED API DOCUMENTATION - DO NOT EDIT
title: mirascope.core.litellm.stream
description: API documentation for mirascope.core.litellm.stream
---

# mirascope.core.litellm.stream

<ApiType type="Module" />

The `LiteLLMStream` class for convenience around streaming LLM calls.

<Info title="Usage">

[Streams](/docs/mirascope/learn/streams)

</Info>

## Classes

### LiteLLMStream

<ApiType type="Class" />

A simple wrapper around `OpenAIStream`.

Everything is the same except updates to the `construct_call_response` method and
the `cost` property so that cost is properly calculated using LiteLLM's cost
calculation method. This ensures cost calculation works for non-OpenAI models.

**Bases:** OpenAIStream

<AttributesTable
  attributes={[
  {
    "name": "cost_metadata",
    "type": "CostMetadata",
    "description": "Returns metadata needed for cost calculation."
  }
]}
  contentSubpath="docs/mirascope"
  currentModule="mirascope.core.litellm.stream"
/>



